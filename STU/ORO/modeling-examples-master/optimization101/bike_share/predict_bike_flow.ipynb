{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "406c2750",
   "metadata": {},
   "source": [
    "# Bike Share Rebalancing With Mathematical Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7e7404",
   "metadata": {},
   "source": [
    "Bike share systems have become an effective commuting method globally for everyday urban dwellers as well as tourists.\n",
    "\n",
    "Citi-Bike in NYC being the largest Bike-Sharing network had 1,588 active stations and 25,575 active bikes in July 2022.\n",
    "\n",
    "Over 3 million rides were completed July 2022 that cover NYC/Hoboken/Jersey City, with around 150,000 active annual members.\n",
    "\n",
    "During rush hours there are many bike stations that have a high demand for bikes, which means their out-flow of bikes is greater than their in-flow in these stations. \n",
    "\n",
    "Meanwhile there are stations that have a high demand for docks (riders return their bikes to these stations) which means their in-flow of bikes is greater than their out-flow.\n",
    "\n",
    "Lack of available bikes or docks in high-demand stations can cause major imbalance in the bike sharing network and result in customer dissatisfaction and lost revenue.\n",
    "\n",
    "To tackle this problem, bikes are relocated between stations to create a balance between supply and demand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdb0fdf",
   "metadata": {},
   "source": [
    "## Problem Statement and Solution Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2142854",
   "metadata": {},
   "source": [
    "Using historical Citi-bike data in NYC and Jersey area during July 2022, we like to know:\n",
    "- What is the demand for bikes per hour at each station during the first week of August?\n",
    "- Knowing the demand, how can we minimize loss of sale?\n",
    "\n",
    "Loss of sale is caused by lack of bikes when customers demand them. So, bikes should be transfered from stations with higher in-flow of bikes to those with higher out-flow of bikes. \n",
    "\n",
    "So, first, number of bikes to be added to or removed from each station during each hour should be determined. Then, the physical transfer of bikes between stations should be scheduled. \n",
    "\n",
    "In this notebook, we'll focus on the first part and at the end, discuss how the second part can be solved.\n",
    "We'll use a mixture of Machine Learning (ML) and Mathematical Optimization (MO) to solve this problem. \n",
    "\n",
    "**Solution Approach**\n",
    "The solution approach is comprised of two steps:\n",
    "- **Step 1**: We use the historical Citi-bike data in NYC and Jersey area during July 2022 and use an ML model to predict the number of in-flow and out-flow of bikes per hour at each station for the first week of August. This notebook accomplishes this step.\n",
    "- **Step 2**: We use an MO model to decide how many bikes should be added to or removed from each station during each hour so that the total loss of sale is minimized. This is done in [bike_rebalancing](bike_rebalancing.ipynb) Notebook.\n",
    "\n",
    "To ensure that everyone can run the notebook with the gurobi restricted license, we reduce the size of the data. To achieve that, we focus on the top 50 stations during the morning rush hours (7 am to 9 am).\n",
    "\n",
    "The top stations are chosen using the PageRank algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bd6f69",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4036b5a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-12T12:18:19.901609Z",
     "start_time": "2022-11-12T12:18:16.625440Z"
    }
   },
   "source": [
    "import datetime\n",
    "import io\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import requests\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.svm import LinearSVR\n",
    "from xgboost import XGBRegressor\n",
    "from zipfile import ZipFile"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "6cb80ad5",
   "metadata": {},
   "source": [
    "# Collect, Analyze, and Create Required Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2cf6bd",
   "metadata": {},
   "source": [
    "## Citi Bike Trip Histories\n",
    "\n",
    "To get Citi Bike trip data:\n",
    "- Go to [this](https://ride.citibikenyc.com/system-data) link\n",
    "- Click the link under Citi Bike Trip Histories\n",
    "- Download \"[202207-citbike-tripdata.csv.zip](https://s3.amazonaws.com/tripdata/202207-citbike-tripdata.csv.zip)\" and \"[JC-202207-citbike-tripdata.csv.zip](https://s3.amazonaws.com/tripdata/JC-202207-citbike-tripdata.csv.zip)\"\n",
    "\n",
    "\n",
    "[July Citi-Bike Monthly Report](https://mot-marketing-whitelabel-prod.s3.amazonaws.com/nyc/July-2022-Citi-Bike-Monthly-Report.pdf) Stats:\n",
    "\n",
    "- Average Bike Fleet: 25,575 Bikes\n",
    "- Active Stations: 1,588\n",
    "- Average Rides/Day: 109,305 - each bike used 4.13 times/day\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e7f1760",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-12T12:18:21.253047Z",
     "start_time": "2022-11-12T12:18:21.242057Z"
    }
   },
   "source": [
    "def download_zip_to_dataframe(url):\n",
    "    response = requests.get(url)\n",
    "    with ZipFile(io.BytesIO(response.content)) as zf:\n",
    "        with zf.open(zf.namelist()[0]) as f:\n",
    "            df = pd.read_csv(f, low_memory=False)\n",
    "    return df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cadc5750",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-12T12:18:56.741692Z",
     "start_time": "2022-11-12T12:18:22.306863Z"
    }
   },
   "source": [
    "# Read the data directly from the url\n",
    "# NYC data\n",
    "nyc_citi_jul_2022 = download_zip_to_dataframe('https://s3.amazonaws.com/tripdata/202207-citbike-tripdata.csv.zip')\n",
    "# Jersey data\n",
    "jersey_citi_jul_2022 = download_zip_to_dataframe('https://s3.amazonaws.com/tripdata/JC-202207-citbike-tripdata.csv.zip')\n",
    "citi_jul_network = pd.concat([nyc_citi_jul_2022, jersey_citi_jul_2022])\n",
    "pd.isnull(citi_jul_network).sum()  # count of null values in each column"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec0bebcf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-12T12:19:04.738859Z",
     "start_time": "2022-11-12T12:18:56.789998Z"
    }
   },
   "source": [
    "# There is a small number of missing end stations. drop them\n",
    "citi_jul_network.dropna(inplace=True)\n",
    "# Found a naming discrepancy 'Broadway\\t& W 48 St' and 'Broadway\\\\t& W 48 St'.\n",
    "# replacing with 'Broadway & W 48 St' so they all match\n",
    "citi_jul_network['start_station_name'] = citi_jul_network['start_station_name'].replace(\n",
    "    ['Broadway\\t& W 48 St'], 'Broadway & W 48 St')\n",
    "citi_jul_network['start_station_name'] = citi_jul_network['start_station_name'].replace(\n",
    "    ['Broadway\\\\t& W 48 St'], 'Broadway & W 48 St')\n",
    "citi_jul_network['end_station_name'] = citi_jul_network['end_station_name'].replace(\n",
    "    ['Broadway\\t& W 48 St'], 'Broadway & W 48 St')\n",
    "citi_jul_network['end_station_name'] = citi_jul_network['end_station_name'].replace(\n",
    "    ['Broadway\\\\t& W 48 St'], 'Broadway & W 48 St')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "3670270d",
   "metadata": {},
   "source": [
    "## Station Information\n",
    "Citi Bike publishes real-time system data which can be retrieved from [this](http://gbfs.citibikenyc.com/gbfs/gbfs.json) link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1f8e80e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-12T12:19:04.786173Z",
     "start_time": "2022-11-12T12:19:04.771167Z"
    }
   },
   "source": [
    "def get_stations_info():\n",
    "    response_api = requests.get('https://gbfs.citibikenyc.com/gbfs/es/station_information.json')\n",
    "    parse_json = json.loads(response_api.text)\n",
    "    stations = parse_json['data']['stations']\n",
    "    stations_dict = {}\n",
    "    for station in stations:\n",
    "        if 'region_id' in station:\n",
    "            stations_dict[station['name']] = {'capacity': station['capacity'],\n",
    "                                              'lat': station['lat'],\n",
    "                                              'lon': station['lon'],\n",
    "                                              'region': station['region_id']}\n",
    "    if 'Broadway\\t& W 48 St' in stations_dict:\n",
    "        stations_dict['Broadway & W 48 St'] = stations_dict.pop('Broadway\\t& W 48 St')  # replace to match other names\n",
    "    stations_info = pd.DataFrame(stations_dict).T\n",
    "    # Drop stations with capacity = 0\n",
    "    stations_info = stations_info.loc[stations_info.capacity > 0]\n",
    "    return stations_info"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12cff6ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-12T12:19:05.414661Z",
     "start_time": "2022-11-12T12:19:04.821035Z"
    }
   },
   "source": [
    "stations_info = get_stations_info()\n",
    "stations_info.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "dc5cd448",
   "metadata": {},
   "source": [
    "## Get Top Stations\n",
    "PageRank is used to get the top stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01fe3c7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-12T12:19:09.087524Z",
     "start_time": "2022-11-12T12:19:05.446537Z"
    }
   },
   "source": [
    "citi_df = citi_jul_network.groupby(['start_station_name', 'end_station_name'], \n",
    "                                   sort=False)['ride_id'].count().reset_index()\n",
    "g = nx.from_pandas_edgelist(citi_df, source='start_station_name', target='end_station_name',\n",
    "                            edge_attr='ride_id', create_using=nx.DiGraph)\n",
    "wpr_scores_fwd = pd.Series(nx.pagerank(g, weight='ride_id')).sort_values(ascending=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "325aa38b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-12T12:19:09.555679Z",
     "start_time": "2022-11-12T12:19:09.135803Z"
    }
   },
   "source": [
    "plt.figure(figsize=(8, 6), dpi=80)\n",
    "plt.xticks(rotation=90)\n",
    "plt.bar(wpr_scores_fwd.index[:20], wpr_scores_fwd.values[:20])\n",
    "plt.title('Top 20 Important Stations')\n",
    "plt.xlabel('Stations')\n",
    "plt.ylabel('PageRank Value')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "a141a0a1",
   "metadata": {},
   "source": [
    "## Combining and Filtering Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fa57158",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-12T12:19:09.618487Z",
     "start_time": "2022-11-12T12:19:09.607019Z"
    }
   },
   "source": [
    "# Grab the top N stations according to importance in the network\n",
    "n = 50  # User can define how many stations to select\n",
    "top_stations = list(wpr_scores_fwd.head(n).index)\n",
    "# Filter stations info for only the top N stations\n",
    "top_stations_info = stations_info[stations_info.index.isin(top_stations)]\n",
    "top_stations_info.shape  # Some stations are not in stations_info"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0709871",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-12T12:19:09.681859Z",
     "start_time": "2022-11-12T12:19:09.667226Z"
    }
   },
   "source": [
    "# There is discrepancy between stations that are retrived from the live station data and \n",
    "# those in citi_jul_network.\n",
    "# So, the station values in `top_station_info` is used as the base\n",
    "top_stations = top_stations_info.index"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bab9a050",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-12T12:19:25.711002Z",
     "start_time": "2022-11-12T12:19:24.018886Z"
    }
   },
   "source": [
    "# Start\n",
    "citi_jul_network_top = citi_jul_network[citi_jul_network['start_station_name'].isin(top_stations)]\n",
    "citi_jul_network_top['started_at'] = pd.to_datetime(citi_jul_network_top['started_at']).dt.round('h')\n",
    "citi_jul_2022_start = citi_jul_network_top.groupby(['start_station_name', 'started_at']).size().rename('start')\n",
    "citi_jul_2022_start.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56b6cb5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-12T12:19:26.532376Z",
     "start_time": "2022-11-12T12:19:25.774624Z"
    }
   },
   "source": [
    "# End\n",
    "citi_jul_network_top = citi_jul_network[citi_jul_network['end_station_name'].isin(top_stations)]\n",
    "citi_jul_network_top['ended_at'] = pd.to_datetime(citi_jul_network_top['ended_at']).dt.round('h')\n",
    "citi_jul_2022_end = citi_jul_network_top.groupby(['end_station_name', 'ended_at']).size().rename('end')\n",
    "citi_jul_2022_end.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e382506e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-12T12:19:29.555636Z",
     "start_time": "2022-11-12T12:19:29.320768Z"
    }
   },
   "source": [
    "# Combining the hourly ride starts and end for each station\n",
    "citi_jul_2022_hourly_combined = pd.concat(\n",
    "    [citi_jul_2022_start, citi_jul_2022_end], axis=1).fillna(0).reset_index().rename(\n",
    "    columns={'level_0': 'station', 'level_1': 'datetime'})\n",
    "citi_jul_2022_hourly_combined.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "633c5112",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-12T12:19:31.119344Z",
     "start_time": "2022-11-12T12:19:30.951917Z"
    }
   },
   "source": [
    "# Cleaning and saving data as full time series\n",
    "data = citi_jul_2022_hourly_combined\n",
    "data = data[data['datetime'].isin(pd.date_range(start='7/1/2022', end='7/31/2022 23:00:00', freq='H'))]\n",
    "new_index = pd.MultiIndex.from_product([data.station.unique(), data.datetime.unique()])\n",
    "clean_full_time_series = data.set_index(\n",
    "    ['station', 'datetime']).reindex(new_index).fillna(0).reset_index().rename(\n",
    "    columns={'level_0': 'station', 'level_1': 'datetime'})\n",
    "clean_full_time_series.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "f9ba5fcb",
   "metadata": {},
   "source": [
    "# Citi-Bike July 2022 ML Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5df46a",
   "metadata": {},
   "source": [
    "## Create Master ML Dataframe\n",
    "This needs to be done for both trips' start and end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f3daad7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-12T12:19:40.577042Z",
     "start_time": "2022-11-12T12:19:40.568892Z"
    }
   },
   "source": [
    "def prep_ml_df(col):\n",
    "    \"\"\"\n",
    "    Flattens out data. Instead of timeseries running down the rows, it runs across the columns.\n",
    "    Grabbing preceding 12 hours for last week, 2 week ago.\n",
    "\n",
    "    Forecasting one week into the future. Hourly -> 168 hours\n",
    "    \"\"\"\n",
    "    mdf = clean_full_time_series[['station', 'datetime', col]].sort_values('datetime')\n",
    "    ml_master_ls = []\n",
    "    hours_prediction_horizon = 168  # hours in a week\n",
    "    num_lagging_windows = hours_prediction_horizon + 12  # 12 hours leading up to time x\n",
    "    # go through each chunk of data by ts_id\n",
    "    for grp, df in mdf.groupby('station'):\n",
    "        # add lagging demand data\n",
    "        for n in range(hours_prediction_horizon, num_lagging_windows + 1):\n",
    "            df[f'{col}_lag_{n}'] = df[col].shift(n)  # one week past\n",
    "            df[f'{col}_lag_{n + 168}'] = df[col].shift(n + 168)  # two\n",
    "        ml_master_ls.append(df)\n",
    "    # bring it all back together\n",
    "    ml_master_df = pd.concat(ml_master_ls, axis=0, ignore_index=True).dropna(axis=0)\n",
    "    return ml_master_df, mdf"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5e4b675",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-12T12:19:42.302660Z",
     "start_time": "2022-11-12T12:19:41.536434Z"
    }
   },
   "source": [
    "# Creating ML dataframe for 'start'\n",
    "ml_master_df_start, master_df_start = prep_ml_df('start')\n",
    "# Creating ML dataframe for 'end'\n",
    "ml_master_df_end, master_df_end = prep_ml_df('end')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "6f97159e",
   "metadata": {},
   "source": [
    "## Split Training and Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7b024d",
   "metadata": {},
   "source": [
    "### Define train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb6868bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-12T12:19:45.398443Z",
     "start_time": "2022-11-12T12:19:45.392442Z"
    }
   },
   "source": [
    "def train_test_data(ml_df, start_end, train_test_cutoff):\n",
    "    \"\"\"Separate the ml_df into training and test sets\n",
    "    \n",
    "    we preserve the training and testing data keys to keep track of our predictions later    \n",
    "    we create the data after the clustering code below    \n",
    "    Note: we should add logic to make sure we dropped start from X_... datasets\n",
    "    \"\"\"\n",
    "    # get model feature data\n",
    "    train_mask = ml_df.datetime < train_test_cutoff\n",
    "    X_train = ml_df[train_mask].copy()\n",
    "    X_test = ml_df[~train_mask].copy()\n",
    "\n",
    "    # get the model targets\n",
    "    y_train = X_train[start_end]\n",
    "    y_test = X_test[start_end]\n",
    "\n",
    "    # drop the unused columns\n",
    "    extra_cols = ['station', 'datetime', start_end]\n",
    "    X_train.drop(extra_cols, axis=1, inplace=True)\n",
    "    X_test.drop(extra_cols, axis=1, inplace=True)\n",
    "    return X_train, y_train, X_test, y_test"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2f69a42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-12T12:19:46.635639Z",
     "start_time": "2022-11-12T12:19:46.601129Z"
    }
   },
   "source": [
    "cutoff_time = datetime.datetime(year=2022, month=7, day=27)\n",
    "# Start\n",
    "X_train_start, y_train_start, X_test_start, y_test_start = train_test_data(ml_master_df_start, 'start', cutoff_time)\n",
    "# End\n",
    "X_train_end, y_train_end, X_test_end, y_test_end = train_test_data(ml_master_df_end, 'end', cutoff_time)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "4bf32a24",
   "metadata": {},
   "source": [
    "## Running ML models and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0b8d297",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-12T12:19:48.348264Z",
     "start_time": "2022-11-12T12:19:48.337141Z"
    }
   },
   "source": [
    "def create_ml_models(x_train, y_train, x_test, y_test):\n",
    "    best_model = None\n",
    "    best_model_name = None\n",
    "    best_score = 0\n",
    "    for name, regression in zip(['xgb', 'svm', 'linear regression'],\n",
    "                                [XGBRegressor, LinearSVR, LinearRegression]):\n",
    "        ml_model = regression()\n",
    "        ml_model.fit(x_train, y_train)\n",
    "        print(f'{name} results\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "        score = r2_score(y_test, ml_model.predict(x_test))\n",
    "        print(score)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_model = ml_model\n",
    "            best_model_name = name\n",
    "    print(f'\\nBest model: {best_model_name}\\n')\n",
    "    return best_model"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1042ef60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-12T12:19:57.532976Z",
     "start_time": "2022-11-12T12:19:53.500568Z"
    }
   },
   "source": [
    "# Start\n",
    "ml_model_start = create_ml_models(X_train_start, y_train_start, X_test_start, y_test_start)\n",
    "# End\n",
    "ml_model_end = create_ml_models(X_train_end, y_train_end, X_test_end, y_test_end)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "303327d4",
   "metadata": {},
   "source": [
    "## Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56cd5866",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-12T12:19:57.814009Z",
     "start_time": "2022-11-12T12:19:57.795560Z"
    }
   },
   "source": [
    "def create_prediction_df(master_df, ml_model, col):\n",
    "    ml_master_ls = []\n",
    "    hours_prediction_horizon = 168  # hours in a week\n",
    "    num_lagging_windows = hours_prediction_horizon + 12  # 12 hours leading up to time x\n",
    "    # go through each chunk of data by ts_id\n",
    "    date_range = pd.date_range(start='8/1/2022', end='8/5/2022 23:00:00', freq='H')\n",
    "    for grp, df in master_df.groupby('station'):\n",
    "        prediction_df = pd.DataFrame({'station': grp, col: 0, 'datetime': date_range})\n",
    "        df = pd.concat([df, prediction_df], axis=0, ignore_index=True)\n",
    "        # assure sorted\n",
    "        df.sort_values('datetime', inplace=True)\n",
    "        # add lagging demand data\n",
    "        for n in range(hours_prediction_horizon, num_lagging_windows + 1):\n",
    "            df[f'{col}_lag_{n}'] = df[col].shift(n)  # one week past\n",
    "            df[f'{col}_lag_{n + 168}'] = df[col].shift(n + 168)  # two\n",
    "        ml_master_ls.append(df)\n",
    "    # bring it all back together\n",
    "    ml_master_df = pd.concat(ml_master_ls, axis=0, ignore_index=True)\n",
    "    prediction_master = ml_master_df[ml_master_df['datetime'].isin(date_range)]\n",
    "    prediction_ml = prediction_master.drop(['station', 'datetime', col], axis=1)  # dataframe for model\n",
    "    # dataframe prediction key as placeholder for forecasts\n",
    "    prediction_key = prediction_master[['station', 'datetime']].copy()\n",
    "    prediction_key[f'{col}_forecast'] = ml_model.predict(prediction_ml)\n",
    "    return prediction_key"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36136b5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-12T12:22:35.956500Z",
     "start_time": "2022-11-12T12:22:35.044628Z"
    }
   },
   "source": [
    "# First week of August, MON-FRI predictions\n",
    "# Creating Prediction dataframe for 'start'\n",
    "start_prediction_key = create_prediction_df(master_df_start, ml_model_start, 'start')\n",
    "# Creating Prediction dataframe for 'end'\n",
    "end_prediction_key = create_prediction_df(master_df_end, ml_model_end, 'end')\n",
    "predictions_final = pd.merge(start_prediction_key, end_prediction_key, on=['station', 'datetime'])\n",
    "top_stations_info.to_csv('top_stations.csv', index_label='station')\n",
    "predictions_final.round(0).to_csv('stations_flow.csv', index=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c765bd",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
